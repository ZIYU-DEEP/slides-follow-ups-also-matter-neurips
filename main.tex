\documentclass[10pt, xcolor=x11names,compress]{beamer}
\usepackage{tabulary}
\usepackage{etoolbox}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{float}
\usepackage{graphicx}
\usepackage{mwe}% for example pictures
\usepackage{siunitx}
\usepackage{hyperref}
\usecolortheme{spruce}
\useoutertheme{infolines}
\usefonttheme[onlymath]{serif}
\setbeamertemplate{headline}[default]
\setbeamertemplate{navigation symbols}{}
\mode<beamer>{\setbeamertemplate{blocks}[rounded][shadow=true]}
\setbeamercovered{transparent}
\input{macros}

%%%%%%%% Set the warning %%%%%%%%
\usepackage{silence}
\WarningFilter[pdftoc]{hyperref}{Token not allowed in a PDF string}
\WarningsOff

%%%%%%%% Set the color %%%%%%%%
\setbeamercolor{block body}{use=structure, fg=white, bg=black!20}
\setbeamercolor{itemize item}{fg=black}
\setbeamercolor{itemize subitem}{fg=gray} 
\setbeamercolor{itemize subsubitem}{fg=black!20} 

%%%%%%%% Set the high-level colorbox %%%%%%%%
\makeatletter\setbeamertemplate{footline}
{  
\leavevmode%  
\hbox{%  

\begin{beamercolorbox}[wd=.5\paperwidth,ht=2.5ex,dp=1ex,center]{author in head/foot}%    
\usebeamerfont{author in head/foot}
\insertshortauthor%~~\beamer@ifempty{\insertshortinstitute}{}
\end{beamercolorbox}%  

\begin{beamercolorbox}[wd=.5\paperwidth,ht=2.5ex,dp=1ex,right]{date in head/foot}%    
\usebeamerfont{date in head/foot}\insertshortdate{}\hspace*{2em}    
\insertframenumber{} / \inserttotalframenumber\hspace*{2ex}   
\end{beamercolorbox}}%  
\vskip0pt%
}

%%%%%%%% Set the first page %%%%%%%%
\makeatother 
\useoutertheme[footline=empty, subsection=false]{miniframes}
\usepackage{multicol}  
\author[C. Wang, Z. Ye, Z. Feng, A. Badanidiyuru, H. Xu]{Chaoqi Wang\inst{1}, Ziyu Ye\inst{1}, Zhe Feng\inst{2}\\Ashwinkumar Badanidiyuru\inst{3}, Haifeng Xu\inst{1}}
\institute[The University of Chicago]{The University of Chicago\inst{1}\vspace{+2pt}\\Google Research\inst{2}\vspace{+2pt}\\Google\inst{3}}
\title{Follow-ups Also Matter:\\Improving Contextual Bandits via Post-serving Contexts}
\date{NeurIPS 2023} 


\begin{document}

\begin{frame}
\titlepage
\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Introduction}
% =======================================
\begin{frame}{Backgrounds}

\begin{itemize}
    \item To give an illustrative example on why post-serving contexts is a practical issue.
    \item To highlight the research question.
\end{itemize}

\end{frame}

\begin{frame}{Contributions}
\begin{itemize}
    \item \textbf{New Problem Setting}: 
    \begin{itemize}
        \item Introduced a new family of contextual bandits with post-serving contexts.
    \end{itemize}
    \item \textbf{Enhanced Lemma}: 
    \begin{itemize}
        \item Developed a generalized version of the Elliptical Potential Lemma (EPL).
    \end{itemize}
    \item \textbf{Theoretical Guarantee}: 
    \begin{itemize}
        \item Designed a new algorithm, \texttt{poLinUCB}, enjoying a regret bound of \( \widetilde{\mathcal{O}}(T^{1-\alpha}d_u^{\alpha} + d_u\sqrt{T K })\).
    \end{itemize}
    \item \textbf{Empirical Validation}: 
    \begin{itemize}
        \item Achieved SOTA performance on synthetic and real-world datasets.
    \end{itemize}
\end{itemize}


% \begin{itemize}
%     \item Introduced a new family of contextual linear bandits with post-serving contexts.
%     \item Developed a robustified and generalized version of the Elliptical Potential Lemma (EPL) to accommodate random noise in the post-serving contexts.
%     \item Designed a new algorithm, \texttt{poLinUCB}, with a regret bound of $ \widetilde{\mathcal{O}}(T^{1-\alpha}d_u^{\alpha} + d_u\sqrt{T K })$, adaptable to the complexity of pre- and post-serving context mapping.
%     \item Validated the algorithm's SOTA performance via synthetic and real-world experiments.
% \end{itemize}

\end{frame}
% =======================================




% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% =======================================
\begin{frame}[label=Background]{Problem Setup and Notations}

\begin{itemize}
    \item \textbf{Problem Setup}: Each time $t = 1, 2, \cdots, T$:
    \begin{itemize}
        \item The learner observes the context $\vx_t$.
        \item The learner selects an arm $a_t \in [K] $.
        \item The learner observes the reward $r_{t,a_t}$ \textbf{and the post-serving context $\vz_t$}.
    \end{itemize}
\end{itemize}

\begin{itemize}
    \item \textbf{Notations}:
    \begin{itemize}
        \item Actions space: $\calA = [K]$.
        
        \item Pre-serving context: $\vx \in \sR^{d_{\vx}}$; post-serving context: $\vz \in \sR^{d_{\vz}}$.
        \begin{itemize}
            \item $\vz = \phi^{\star}\left(\vx_t\right)+\vepsilon_t, \text{and } \phi^{\star}(\vx)=\sE[\vz \mid \vx]$
        \end{itemize}
        
        \item Reward function: 
        \begin{itemize}
            \item $r_{a}(\vx, \vz) = \vx^\top \vtheta_a^\star + \vz^\top \vbeta_a^\star + \eta$, where $\eta$ is $R_{\eta}$-sub-Gaussian.
        \end{itemize}
        
        \item Matrix representation: 
        \begin{itemize}
            \item $\mX_{t} = \sum_{s=1}^t \vx_s\vx_s^\top + \lambda \mI$ and $\mZ_t = \sum_{s=1}^t \vz_s \vz_s^\top + \lambda \mI$.
        \end{itemize}
        
        \item Norm restrictions: 
        \begin{itemize}
            \item $\forall a \in \calA, \|\vtheta_a^\star\|_2\leq 1, \|\vbeta_{a}^\star\|_2\leq 1 $; $\|\vx\|_2\leq L_x, \|\vz\|_2 \leq L_z$.
        \end{itemize}
        
    \end{itemize}
\end{itemize}

\end{frame}
% =======================================

% =======================================


\begin{frame}{Assumption: Generalized learnability of $\phi^*$}

TODO: make this more abstract and easily digested by the audience.

There exists an algorithm that, given $t$ pairs of examples $\{(\vx_s, \vz_s)\}_{s=1}^t$ with  arbitrarily chosen $\vx_s$'s,   outputs an estimated function of $\phi^\star: \mathbb{R}^{d_x} \rightarrow \mathbb{R}^{d_z}$ such that for any $\vx\in \mathbb{R}^{d_x}$,  the following holds with probability at least $1-\delta$, 

\begin{align}
     e_t^\delta:=\left\|\widehat{\phi}_t(\boldsymbol{x})-\phi^{\star}(\boldsymbol{x})\right\|_2 \leq C_0 \cdot\left(\|\boldsymbol{x}\|_{\boldsymbol{X}_t^{-1}}^2\right)^\alpha \cdot \log (t / \delta), \nonumber
\end{align}
where $\alpha \in (0, 1/2]$ and $C_0$ is some universal constant. 

\end{frame}
% =======================================


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Method}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% =======================================
\begin{frame}[label=warmup]{Warmup: Why Natural Attempts May be Inadequate?}

\end{frame}
% =======================================

% =======================================
\begin{frame}{Generalized Elliptical Potential Lemma}

\end{frame}
% =======================================

% =======================================
\begin{frame}{The Proposed Algorithm: \texttt{poLinUCB}}

\end{frame}
% =======================================


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% =======================================
\begin{frame}{Regret Analysis}

\end{frame}
% =======================================

% =======================================
\begin{frame}{Experimental Results}

\end{frame}
% =======================================

% =======================================
\begin{frame}
 \begin{center}
		{\Huge Thank you.}
		%\bigskip\bigskip % Vertical whitespace
	\end{center}
\end{frame}
% =======================================

\end{document}