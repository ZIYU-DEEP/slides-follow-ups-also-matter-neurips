% =============== Set the basic ============== %
\documentclass[10pt, xcolor={dvipsnames,x11names},compress]{beamer}
\usepackage{tikz}
\usepackage{tabulary}
\usepackage{algorithm,algpseudocode}
\usepackage{etoolbox}
\usepackage{booktabs}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{float}
\usepackage{graphicx}
\usepackage{mwe}
\usepackage{siunitx}
\usepackage{hyperref}
\usepackage{biblatex}
\addbibresource{main.bib}
\usecolortheme{spruce}
\useoutertheme{infolines}
\usefonttheme[onlymath]{serif}
\setbeamertemplate{headline}[default]
\setbeamertemplate{navigation symbols}{}
\mode<beamer>{\setbeamertemplate{blocks}[rounded][shadow=true]}
\setbeamercovered{transparent}
\input{macros}

% =============== Set the caption ============== %
\definecolor{sad}{RGB}{0,51,0}
\usepackage[textfont={small}]{caption}
\usepackage[labelfont={color=sad}]{caption}
\setbeamertemplate{caption}[numbered]

\definecolor{alizarin}{RGB}{227,38,54}
\definecolor{ultramarine}{RGB}{24,13,191}
\definecolor{navyblue}{rgb}{0.0, 0.0, 0.5}
\definecolor{dgreen}{RGB}{0,51,0}

% \hypersetup{linkcolor=alizarin, 
%             citecolor=ultramarine, 
%             urlcolor=dgreen,
%             colorlinks=true,}

% =============== Set the warning ============== %
\usepackage{silence}
\WarningFilter[pdftoc]{hyperref}{Token not allowed in a PDF string}
\WarningsOff

% =============== Set the color =============== %
\setbeamercolor{block body}{use=structure, fg=white, bg=black!20}
\setbeamercolor{itemize item}{fg=black}
\setbeamercolor{itemize subitem}{fg=gray} 
\setbeamercolor{itemize subsubitem}{fg=black!20} 

% ========= Set up highlighters ========= %
\newcommand{\emphgreen}[1]{\colorbox{Green3!30!white}{$\displaystyle#1$}}
\newcommand{\emphgold}[1]{\colorbox{Goldenrod!50}{$\displaystyle#1$}}
\newcommand{\emphmelon}[1]{\colorbox{Melon!50}{$\displaystyle#1$}}
\newcommand{\emphapricot}[1]{\colorbox{Apricot!50}{$\displaystyle#1$}}
\newcommand{\emphmarine}[1]{\colorbox{Aquamarine!50}{$\displaystyle#1$}}
\newcommand{\emphsky}[1]{\colorbox{SkyBlue!50}{$\displaystyle#1$}}
\newcommand{\emphgray}[1]{\colorbox{gray!10}{$\displaystyle#1$}}
\newcommand{\emphpurple}[1]{\colorbox{purple!10}{$\displaystyle#1$}}
\newcommand{\emphred}[1]{\colorbox{Red!30}{$\displaystyle#1$}}


% =========Set the high-level colorbox ========= %
\makeatletter\setbeamertemplate{footline}
{  
\leavevmode%  
\hbox{%  

\begin{beamercolorbox}[wd=.5\paperwidth,ht=2.5ex,dp=1ex,center]{author in head/foot}%    
\usebeamerfont{author in head/foot}
\insertshortauthor%~~\beamer@ifempty{\insertshortinstitute}{}
\end{beamercolorbox}%  

\begin{beamercolorbox}[wd=.5\paperwidth,ht=2.5ex,dp=1ex,right]{date in head/foot}%    
\usebeamerfont{date in head/foot}\insertshortdate{}\hspace*{2em}    
\insertframenumber{} / \inserttotalframenumber\hspace*{2ex}   
\end{beamercolorbox}}%  
\vskip0pt%
}

% ========= Set the first page ========= %
\makeatother 
\useoutertheme[footline=empty, subsection=false]{miniframes}
\usepackage{multicol}  
\author[C. Wang, Z. Ye, Z. Feng, A. Badanidiyuru, H. Xu]{Chaoqi Wang\inst{1}, Ziyu Ye\inst{1}, Zhe Feng\inst{2},\\Ashwinkumar Badanidiyuru\inst{3}, Haifeng Xu\inst{1}}
\institute[The University of Chicago]{The University of Chicago\inst{1}\vspace{+2pt}\\Google Research\inst{2}\vspace{+2pt}\\Google\inst{3}}
\title{Follow-ups Also Matter:\\Improving Contextual Bandits via Post-serving Contexts}
\date{NeurIPS 2023} 


\begin{document}

\begin{frame}
\titlepage
\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Introduction}
% =======================================
\begin{frame}
    \frametitle{Background}
    \begin{minipage}[t]{\textwidth}
        \centering
            \vspace{-30pt}
            \begin{figure}
                \includegraphics[width=0.5\linewidth]{figs/ex-followup.png}
                \caption{{\small Illustration of learning with post-serving contexts.}}
            \end{figure}
    \end{minipage}

    \vspace{0.5cm} % Space between top and bottom

    % Bottom part for text
    \begin{minipage}[t]{\textwidth}
        \begin{itemize}
            \item \textbf{Motivation}: Post-serving contexts are prevalent in recommender systems.
            \item \textbf{Challenges}: Classical bandit algorithms often fall short in such scenarios.
            \item \textbf{Research question}: How to effectively utilizing post-serving information in contextual bandits?
        \end{itemize}
    \end{minipage}

\end{frame}
% =======================================

% =======================================
\begin{frame}[label=Background]{Problem Setup and Notations}

\begin{itemize}
    \item \textbf{Problem Setup}: Each time $t = 1, 2, \cdots, T$:
    \begin{itemize}
        \item The learner observes the context $\vx_t$.
        \item The learner selects an arm $a_t \in [K] $.
        \item The learner observes the reward $r_{t,a_t}$ \underline{\textcolor{sad}{\textbf{and the post-serving context $\vz_t$}}}.
    \end{itemize}
\end{itemize}


\begin{itemize} \color{gray}
    \item \textbf{Notations}:
    \begin{itemize} \color{gray}
        \item Actions space: $\calA = [K]$.
        
        \item Pre-serving context: $\vx \in \sR^{d_{\vx}}$; post-serving context: $\vz \in \sR^{d_{\vz}}$.
        \begin{itemize} \color{gray}
            \item $\vz = \phi^{\star}\left(\vx_t\right)+\vepsilon_t, \text{and } \phi^{\star}(\vx)=\sE[\vz \mid \vx]$
        \end{itemize}
        
        \item Reward function: 
        \begin{itemize} \color{gray}
            \item $r_{a}(\vx, \vz) = \vx^\top \vtheta_a^\star + \vz^\top \vbeta_a^\star + \eta$, where $\eta$ is $R_{\eta}$-sub-Gaussian.
        \end{itemize}
        
        \item Matrix representation: 
        \begin{itemize} \color{gray}
            \item $\mX_{t} = \sum_{s=1}^t \vx_s\vx_s^\top + \lambda \mI$ and $\mZ_t = \sum_{s=1}^t \vz_s \vz_s^\top + \lambda \mI$.
        \end{itemize}
        
        \item Norm restrictions: 
        \begin{itemize} \color{gray}
            \item $\forall a \in \calA, \|\vtheta_a^\star\|_2\leq 1, \|\vbeta_{a}^\star\|_2\leq 1 $; $\|\vx\|_2\leq L_x, \|\vz\|_2 \leq L_z$.
        \end{itemize}
        
    \end{itemize}
\end{itemize}

\end{frame}
% =======================================


% =======================================
\begin{frame}{Contributions}
\begin{itemize}
    \item \textbf{New framework}: 
    \begin{itemize}
        \item Proposed a novel family of contextual bandits with post-serving contexts.
    \end{itemize}
    \item \textbf{Enhanced lemma}: 
    \begin{itemize}
        \item Introduced the Generalized Elliptical Potential Lemma (EPL).
    \end{itemize}
    \item \textbf{Algorithm and theory}: 
    \begin{itemize}
        \item Designed \textbf{\polinucb} with a regret bound of \( \widetilde{\mathcal{O}}(T^{1-\alpha}d_u^{\alpha} + d_u\sqrt{T K })\).
    \end{itemize}
    \item \textbf{Empirical validation}: 
    \begin{itemize}
        \item Achieved SOTA performance on synthetic and real-world datasets.
    \end{itemize}
\end{itemize}
% =======================================


\end{frame}
% =======================================




% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Preliminaries}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


% =======================================


\begin{frame}{Assumption: Generalized learnability of $\phi^*$}

TODO: make this more abstract and easily digested by the audience.\\

There exists an algorithm that, given $t$ pairs of examples $\{(\vx_s, \vz_s)\}_{s=1}^t$ with  arbitrarily chosen $\vx_s$'s,   outputs an estimated function of $\phi^\star: \mathbb{R}^{d_x} \rightarrow \mathbb{R}^{d_z}$ such that for any $\vx\in \mathbb{R}^{d_x}$,  the following holds with probability at least $1-\delta$, 

\begin{align}
     e_t^\delta:=\left\|\widehat{\phi}_t(\boldsymbol{x})-\phi^{\star}(\boldsymbol{x})\right\|_2 \leq C_0 \cdot\left(\|\boldsymbol{x}\|_{\boldsymbol{X}_t^{-1}}^2\right)^\alpha \cdot \log (t / \delta), \nonumber
\end{align}
where $\alpha \in (0, 1/2]$ and $C_0$ is some universal constant. 

\end{frame}
% =======================================

% =======================================
\begin{frame}[label=warmup]{Warmup: Why Natural Attempts May be Inadequate?}

\end{frame}
% =======================================

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Method}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% =======================================
\begin{frame}{Generalized Elliptical Potential Lemma}
TODO: make this more abstract and easily digested by the audience.\\
Suppose (1) $\mX_0 \in \mathbb{R}^{d \times d}$ is any positive definite matrix; (2) $\vx_1, \ldots, \vx_T \in \mathbb{R}^d$ is a sequence of vectors with bounded $l_2$ norm $\max_t \|\vx_t\| \leq L_x$; (3) $\vepsilon_1, \ldots, \vepsilon_T \in \mathbb{R}^d$ is a sequence of independent (not necessarily identical) bounded zero-mean   noises satisfying  $\max_{t} \|\vepsilon_t\| \leq L_{\epsilon}$ and $   \expect[\vepsilon_t \vepsilon_t^\top] \succcurlyeq \sigma^2_{\epsilon} \mI$ for any $t$; %(4)  $\varphi: \mathbb{R}^D \to \mathbb{R}^d$ is a convex context mapping function; 
and (4) $\widetilde{\mX}_t$ is defined as follows:
\begin{equation*}\label{eq:data-matrix-GEPL}
    \widetilde{\mX}_t=\mX_0+\sum_{s=1}^t  (\vx_s + \vepsilon_s)  (\vx_s + \vepsilon_s)^{\top} \in \mathbb{R}^{d \times d}. 
\end{equation*} 
Then, for any $p \in [0, 1]$, the following inequality holds with probability at least $1-\delta$,
{\scriptsize
\begin{align}\label{eq:gepl-bound}
    \!\!\!\!\!\!\!\!\sum_{t=1}^T\left(1 \wedge\left\| \vx_t \right\|_{\widetilde{\mX}_{t-1}^{-1}}^2\right)^p &\leq  2^p T^{1-p}\log^p\left(\frac{\det \mX_T}{\det\mX_0}\right) +  \frac{  8 L_\epsilon^2 (L_\epsilon + L_x)^2 }{\sigma_{\epsilon}^4} \log\left(\frac{32d L_\epsilon^2 (L_\epsilon + L_x)^2 }{\delta \sigma_{\epsilon}^4}\right).  \nonumber
\end{align}}


\end{frame}
% =======================================

% =======================================
\begin{frame}{The Proposed Algorithm: \polinucb}
\hspace{+10pt}
\begin{center}

\scalebox{0.8}{\begin{minipage}[c][0.3\paperheight][c]{1.2\textwidth}
  \centering

\begin{algorithm}[H]
\caption{\polinucb~(Linear UCB with post-serving contexts)}\label{alg:polinucb}
\begin{algorithmic}[1]
    % \textbf{Input:} Text Document.\newline
    % \textbf{Output:} Summary sentences.
    \State{Initialize parameters $\left\{\boldsymbol{A}_{i, 0} \leftarrow \mathbf{I}^d, \boldsymbol{b}_{i, 0} \leftarrow \mathbf{0}^d\right\}$ for all $i \in[K]$ and $\alpha \in \mathbb{R}^{+}$.}
    \For{$t=0, 1, \ldots, T$}
        \State Receive the pre-serving context $\vx _{t}$.
        \State Compute the optimistic parameters by maximizing the UCB objective:
        $${\left(a_t, {\widetilde{\phi}_{t}(\vx_t)}, \widetilde{\vw}_t\right) = {\underset{(a, \phi, \vw_a) \in [K] \times \calC_{t-1}\left(\widehat{\phi}_{t-1}, \vx_t\right) \times \calC_{t-1}(\widehat{\vw}_{t-1,a})  }{\argmax}} { \begin{bmatrix} \vx_t \\ \phi(\vx_t) \end{bmatrix}^\top \vw_{a} }}.$$ 
        \State Play the arm $a_t$ and receive the post-serving context  $\vz_t$ and  the reward $r_{t, a_t}$.
        \State Compute $\widehat{\vw}_{t,a}$ for each $a \in \calA$ using:
        $$\emphgray{
        \ell_t\left(\boldsymbol{\theta}_a, \beta_a\right)=\sum_{s \in[t]: a_s=a}\left(r_{s, a}-\boldsymbol{x}_s^{\top} \boldsymbol{\theta}_a-\emphgreen{\vz_s}^{\top} \beta_a\right)^2+\lambda\left(\left\|\boldsymbol{\theta}_a\right\|_2^2+\left\|\beta_a\right\|_2^2\right)}.
        $$
        \State Compute the estimated post-serving context generating function $\widehat{\phi}_t(\cdot)$ using ERM. 
        \State Update confidence sets $\calC_t(\widehat{\vw}_{t, a})$ and $\calC_t(\widehat{\phi}_t, \vx_t)$ for each $a$.
    \EndFor

\end{algorithmic}
\end{algorithm}
\end{minipage}
}
\end{center}
\end{frame}
% =======================================


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% =======================================
\begin{frame}{Regret Analysis}

\begin{table}[]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Settings}  & \textbf{Ours} \\ \midrule
Ours               & $\widetilde{\mathcal{O}}\left(T^{1-\alpha}d_u^{\alpha} + d_u\sqrt{T K }\right)$           \\
Action-dependent contexts   & $\widetilde{\mathcal{O}}\left(T^{1-\alpha}d_u^{\alpha}\sqrt{K} + d_u\sqrt{T K }\right)$            \\
Same setting as in [Abbasi et al., 2011]~\footfullcite{abbasi2011improved} & $\widetilde{\mathcal{O}}\left(T^{1-\alpha}d_u^{\alpha} + d_u\sqrt{T  }\right)$            \\ \bottomrule
\end{tabular}
\caption{Upper bound of regret of \polinucb.}
\label{tab:regret}
\end{table}
\end{frame}
% =======================================

% =======================================
\begin{frame}{Experimental Results}

\begin{itemize}
    \item  Our proposed \polinucb consistently outperforms other strategies\\\textcolor{gray}{{\footnotesize (except for \texttt{LinUCB} ($x$ and $z$) which equips with post-serving contexts in arm selection)}}.
\end{itemize}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.85\textwidth]{figs/synthetic-comparisons.pdf}
    \vspace{0.2cm}
    \caption{{\small Cumulative Regret in three synthetic environments. The shaded area denotes the standard error computed using 10 different random seeds.}}
    \label{fig:synthetic-experiments}
\end{figure}

\end{frame}
% =======================================

% =======================================
\begin{frame}
 \begin{center}
		{\Huge \qquad \ \ Thank you.}
		\bigskip\bigskip % Vertical whitespace
  \newline
        \bigskip Please refer to our paper for more information:\\
        \href{https://arxiv.org/abs/2309.13896}{https://arxiv.org/abs/2309.13896}.
	\end{center}
\end{frame}
% =======================================

\end{document}